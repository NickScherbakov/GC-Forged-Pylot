requests>=2.25.0
tqdm>=4.61.0
numpy>=1.19.0
python-dotenv>=0.19.0
pydantic>=1.9.0
fastapi>=0.68.0
uvicorn[standard]>=0.15.0
llama-cpp-python>=0.3.0
psutil>=5.8.0
pytest>=6.2.5
httpx>=0.19.0
wmi>=1.5.1; sys_platform == "win32"  # For hardware detection on Windows
gitpython>=3.1.0  # For downloading llama.cpp sources
pyinstaller>=5.0.0; sys_platform == "win32"  # For packaging application on Windows
py-cpuinfo>=8.0.0  # Alternative method for getting CPU information
jsonschema>=4.0.0