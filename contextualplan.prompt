# GC-Forged-Pylot: Контекстный промпт

## 1. О ПРОЕКТЕ
GC-Forged-Pylot - это автономная система программирования, работающая 24/7, построенная на основе llama.cpp от Георгия Герганова и расширенная возможностями GitHub Copilot.

## 2. АРХИТЕКТУРА СИСТЕМЫ
- GC-Core: Оптимизированный llama.cpp сервер с улучшениями для интеграции с IDE
- Forged-Bridge: Продвинутый прокси-слой для бесшовной интеграции с расширениями VSCode
- Pylot-Agent: Автономный агент, способный выполнять долгосрочные задачи программирования

## 3. СТРУКТУРА ПРОЕКТА
/
├── src/
│   ├── core/           # Компонент ядра (llama.cpp интеграция)
│   ├── bridge/         # Компонент моста (взаимодействие с IDE)
│   └── pylot-agent/    # Компонент автономного агента
├── docs/               # Документация
├── scripts/            # Вспомогательные скрипты
├── models/             # Директория для моделей
└── [корневые файлы]    # Конфигурация, README, etc.

## 4. ЭТАПЫ РАЗРАБОТКИ
1. ✓ Создание структуры каталогов и базовых файлов
2. → Реализация GC-Core (llama.cpp интеграция)
3. → Реализация Forged-Bridge (VSCode интеграция)
4. → Реализация Pylot-Agent (автономная работа)
5. → Тестирование и отладка
6. → Документация и примеры использования

## 5. ТЕКУЩАЯ ЗАДАЧА
[Текущая задача, над которой мы работаем]

# GC-Forged-Pylot: Контекстный промпт

## 1. О ПРОЕКТЕ
GC-Forged-Pylot - это автономная система программирования, работающая 24/7, построенная на основе llama.cpp от Георгия Гергакова и расширенная возможностями GitHub Copilot.

## 2. АРХИТЕКТУРА СИСТЕМЫ
- GC-Core: Оптимизированный llama.cpp сервер с улучшениями для интеграции с IDE
- Forged-Bridge: Продвинутый прокси-слой для бесшовной интеграции с расширениями VSCode
- Pylot-Agent: Автономный агент, способный выполнять долгосрочные задачи программирования

## 3. СТРУКТУРА ПРОЕКТА
/
├── src/
│   ├── core/           # Компонент ядра (llama.cpp интеграция)
│   ├── bridge/         # Компонент моста (взаимодействие с IDE)
│   └── pylot-agent/    # Компонент автономного агента
├── docs/               # Документация
├── scripts/            # Вспомогательные скрипты
├── models/             # Директория для моделей
└── [корневые файлы]    # Конфигурация, README, etc.

## 4. ЭТАПЫ РАЗРАБОТКИ
1. ✓ Создание структуры каталогов и базовых файлов
2. → Реализация GC-Core (llama.cpp интеграция)
3. → Реализация Forged-Bridge (VSCode интеграция)
4. → Реализация Pylot-Agent (автономная работа)
5. → Тестирование и отладка
6. → Документация и примеры использования

## 5. ТЕКУЩАЯ ЗАДАЧА
Реализация GC-Core (llama.cpp интеграция) - создание базовой функциональности для запуска и взаимодействия с llama.cpp

### Выполнено:
- Создана структура проекта
- Добавлен файл core/__init__.py
- Добавлен файл core/server.py (базовая реализация LlamaServer)
- Добавлен файл core/inference.py (обработка вызовов LLM модели)

### Следующие шаги:
1. Добавить core/api.py для REST API интерфейса
2. Обновить core/config.py для оптимизации под оборудование (Intel i9-11900KF, AMD RX 580, 48GB RAM)
3. Настроить интеграцию с llama-cpp-python с поддержкой AMD GPU через ROCm

## 6. ОБОРУДОВАНИЕ И СИСТЕМНЫЕ ТРЕБОВАНИЯ
- CPU: Intel Core i9-11900KF @ 3.50GHz (11th Gen)
- GPU: AMD Radeon RX 580 2048SP с 4GB VRAM
- RAM: ~48GB (51,539,607,552 байт) в 4 модулях
- OS: Windows Server 2022 (машина WS2022-04)

# GC-Forged-Pylot: Контекстный промпт

## 1. О ПРОЕКТЕ
GC-Forged-Pylot - это автономная система программирования, работающая 24/7, построенная на основе llama.cpp от Георгия Гергакова и расширенная возможностями GitHub Copilot.

## 2. АРХИТЕКТУРА СИСТЕМЫ
- GC-Core: Оптимизированный llama.cpp сервер с улучшениями для интеграции с IDE
- Forged-Bridge: Продвинутый прокси-слой для бесшовной интеграции с расширениями VSCode
- Pylot-Agent: Автономный агент, способный выполнять долгосрочные задачи программирования

## 3. СТРУКТУРА ПРОЕКТА
/
├── src/
│   ├── core/           # Компонент ядра (llama.cpp интеграция)
│   ├── bridge/         # Компонент моста (взаимодействие с IDE)
│   └── pylot-agent/    # Компонент автономного агента
├── docs/               # Документация
├── scripts/            # Вспомогательные скрипты
├── models/             # Директория для моделей
└── [корневые файлы]    # Конфигурация, README, etc.

## 4. ЭТАПЫ РАЗРАБОТКИ
1. ✓ Создание структуры каталогов и базовых файлов
2. → Реализация GC-Core (llama.cpp интеграция)
3. → Реализация Forged-Bridge (VSCode интеграция)
4. → Реализация Pylot-Agent (автономная работа)
5. → Тестирование и отладка
6. → Документация и примеры использования

## 5. ТЕКУЩАЯ ЗАДАЧА
Реализация GC-Core (llama.cpp интеграция) - создание базовой функциональности для запуска и взаимодействия с llama.cpp

### Выполнено:
- 2025-04-28 12:14 - Создана структура проекта
- 2025-04-28 12:20 - Добавлен файл core/__init__.py
- 2025-04-28 12:25 - Добавлен файл core/server.py (базовая реализация LlamaServer)
- 2025-04-28 12:30 - Добавлен файл core/inference.py (обработка вызовов LLM модели)
- 2025-04-28 12:40 - Добавлен файл core/api.py (REST API и WebSocket интерфейс)

### Следующие шаги:
1. Обновить core/config.py для оптимизации под оборудование (Intel i9-11900KF, AMD RX 580, 48GB RAM)
2. Настроить интеграцию с llama-cpp-python с поддержкой AMD GPU через ROCm
3. Добавить примеры использования API

## 6. ОБОРУДОВАНИЕ И СИСТЕМНЫЕ ТРЕБОВАНИЯ
- CPU: Intel Core i9-11900KF @ 3.50GHz (11th Gen)
- GPU: AMD Radeon RX 580 2048SP с 4GB VRAM
- RAM: ~48GB (51,539,607,552 байт) в 4 модулях
- OS: Windows Server 2022 (машина WS2022-04)

# GC-Forged-Pylot: Контекстный промпт

## 1. О ПРОЕКТЕ
GC-Forged-Pylot - это автономная система программирования, работающая 24/7, построенная на основе llama.cpp от Георгия Гергакова и расширенная возможностями GitHub Copilot.

## 2. АРХИТЕКТУРА СИСТЕМЫ
- GC-Core: Оптимизированный llama.cpp сервер с улучшениями для интеграции с IDE
- Forged-Bridge: Продвинутый прокси-слой для бесшовной интеграции с расширениями VSCode
- Pylot-Agent: Автономный агент, способный выполнять долгосрочные задачи программирования

## 3. СТРУКТУРА ПРОЕКТА
/
├── src/
│   ├── core/           # Компонент ядра (llama.cpp интеграция)
│   ├── bridge/         # Компонент моста (взаимодействие с IDE)
│   └── pylot-agent/    # Компонент автономного агента
├── docs/               # Документация
├── scripts/            # Вспомогательные скрипты
├── models/             # Директория для моделей
└── [корневые файлы]    # Конфигурация, README, etc.

## 4. ЭТАПЫ РАЗРАБОТКИ
1. ✓ Создание структуры каталогов и базовых файлов
2. → Реализация GC-Core (llama.cpp интеграция)
3. → Реализация Forged-Bridge (VSCode интеграция)
4. → Реализация Pylot-Agent (автономная работа)
5. → Тестирование и отладка
6. → Документация и примеры использования

## 5. ТЕКУЩАЯ ЗАДАЧА
Реализация GC-Core (llama.cpp интеграция) - создание базовой функциональности для запуска и взаимодействия с llama.cpp

### Выполнено:
- 2025-04-28 12:14 - Создана структура проекта
- 2025-04-28 12:20 - Добавлен файл core/__init__.py
- 2025-04-28 12:25 - Добавлен файл core/server.py (базовая реализация LlamaServer)
- 2025-04-28 12:30 - Добавлен файл core/inference.py (обработка вызовов LLM модели)
- 2025-04-28 12:40 - Добавлен файл core/api.py (REST API и WebSocket интерфейс)
- 2025-04-28 12:50 - Добавлен файл core/config.py (конфигурация с автоопределением и оптимизацией под оборудование)

### Следующие шаги:
1. Создать requirements.txt с необходимыми зависимостями (llama-cpp-python, fastapi, uvicorn, psutil, wmi)
2. Добавить файл main.py для запуска сервера
3. Создать скрипт setup.py для установки пакета
4. Добавить примеры использования API

## 6. ОБОРУДОВАНИЕ И СИСТЕМНЫЕ ТРЕБОВАНИЯ
- CPU: Intel Core i9-11900KF @ 3.50GHz (11th Gen)
- GPU: AMD Radeon RX 580 2048SP с 4GB VRAM
- RAM: ~48GB (51,539,607,552 байт) в 4 модулях
- OS: Windows Server 2022 (машина WS2022-04)

# GC-Forged-Pylot: Контекстный промпт

## 1. О ПРОЕКТЕ
GC-Forged-Pylot - это автономная система программирования, работающая 24/7, построенная на основе llama.cpp от Георгия Гергакова и расширенная возможностями GitHub Copilot.

## 2. АРХИТЕКТУРА СИСТЕМЫ
- GC-Core: Оптимизированный llama.cpp сервер с улучшениями для интеграции с IDE
- Forged-Bridge: Продвинутый прокси-слой для бесшовной интеграции с расширениями VSCode
- Pylot-Agent: Автономный агент, способный выполнять долгосрочные задачи программирования

## 3. СТРУКТУРА ПРОЕКТА
/
├── src/
│   ├── core/           # Компонент ядра (llama.cpp интеграция)
│   ├── bridge/         # Компонент моста (взаимодействие с IDE)
│   └── pylot-agent/    # Компонент автономного агента
├── docs/               # Документация
├── scripts/            # Вспомогательные скрипты
├── models/             # Директория для моделей
└── [корневые файлы]    # Конфигурация, README, etc.

## 4. ЭТАПЫ РАЗРАБОТКИ
1. ✓ Создание структуры каталогов и базовых файлов
2. → Реализация GC-Core (llama.cpp интеграция)
3. → Реализация Forged-Bridge (VSCode интеграция)
4. → Реализация Pylot-Agent (автономная работа)
5. → Тестирование и отладка
6. → Документация и примеры использования

## 5. ТЕКУЩАЯ ЗАДАЧА
Реализация GC-Core (llama.cpp интеграция) - создание базовой функциональности для запуска и взаимодействия с llama.cpp

### Выполнено:
- 2025-04-28 12:14 - Создана структура проекта
- 2025-04-28 12:20 - Добавлен файл core/__init__.py
- 2025-04-28 12:25 - Добавлен файл core/server.py (базовая реализация LlamaServer)
- 2025-04-28 12:30 - Добавлен файл core/inference.py (обработка вызовов LLM модели)
- 2025-04-28 12:40 - Добавлен файл core/api.py (REST API и WebSocket интерфейс)
- 2025-04-28 12:50 - Добавлен файл core/config.py (конфигурация с автоопределением и оптимизацией под оборудование)
- 2025-04-28 12:55 - Добавлен файл requirements.txt с необходимыми зависимостями

### Следующие шаги:
1. Добавить файл main.py для запуска сервера
2. Создать скрипт setup.py для установки пакета
3. Добавить примеры использования API

## 6. ОБОРУДОВАНИЕ И СИСТЕМНЫЕ ТРЕБОВАНИЯ
- CPU: Intel Core i9-11900KF @ 3.50GHz (11th Gen)
- GPU: AMD Radeon RX 580 2048SP с 4GB VRAM
- RAM: ~48GB (51,539,607,552 байт) в 4 модулях
- OS: Windows Server 2022 (машина WS2022-04)